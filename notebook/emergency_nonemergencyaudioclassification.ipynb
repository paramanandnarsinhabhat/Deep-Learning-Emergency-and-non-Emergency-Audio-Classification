{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overview\n",
    "#* Work with the audio data\n",
    "#* Represent an audio data - Time Domain and Spectrogram\n",
    "#* Build a deep learning model while working with audio data\n",
    "\n",
    "# Understanding the Problem Statement\n",
    "\n",
    "'''\n",
    "According to the National Crime Records Bureau, nearly 24,012 people die each day due to a delay in getting medical assistance. Many accident victims wait for help at the site, and a delay costs them their lives. The reasons could range from ambulances stuck in traffic to the fire brigade not being able to reach the site on time due to traffic jams. \n",
    "\n",
    "The solution to the above problem is to create a system that automatically detects the emergency vehicle prior to reaching the traffic signals and change the traffic signals accordingly.\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "# Dataset\n",
    "'''\n",
    "Download the dataset from [here](https://drive.google.com/file/d/1VBI_X6GyYvf8j3T70-_hVDyhR_sUzeCr/view?usp=sharing)\n",
    "\n",
    "<br>\n",
    "\n",
    "## Import Libraries\n",
    "\n",
    "Let us first import the libraries into our environment\n",
    "\n",
    "* **Librosa** is an open source library in Python that is used for audio and music analyis\n",
    "\n",
    "* **Scipy** is a python library for scientific & technical computing. It contains modules for signal processing, image processing, and linear algebera\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "# For audio processing\n",
    "import librosa\n",
    "import scipy\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "print(librosa.__version__)\n",
    "print(scipy.__version__)\n",
    "\n",
    "# For playing audio\n",
    "import IPython.display as ipd\n",
    "\n",
    "# For array processing\n",
    "import numpy as np\n",
    "\n",
    "# For visualization \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "\n",
    "\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Specify the path to the zip file\n",
    "zip_file_path = 'data/audio.zip'\n",
    "\n",
    "# Specify the directory to extract to\n",
    "extract_to_dir = 'data/unzipped_contents'\n",
    "\n",
    "# Create a directory to extract to if it doesn't exist\n",
    "os.makedirs(extract_to_dir, exist_ok=True)\n",
    "\n",
    "# Open the zip file\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    # Extract all the contents into the directory\n",
    "    zip_ref.extractall(extract_to_dir)\n",
    "    \n",
    "    # List the contents of the extracted folder\n",
    "    print(f\"Contents of the zip file '{zip_file_path}':\")\n",
    "    for file_name in zip_ref.namelist():\n",
    "        print(file_name)\n",
    "\n",
    "# import emergency vehicle data\n",
    "path='data/audio/emergency.wav'\n",
    "emergency,sample_rate = librosa.load(path, sr = 16000)\n",
    "\n",
    "\n",
    "# import non-emergency vehicle data\n",
    "path='data/audio/nonemergency.wav'\n",
    "non_emergency,sample_rate = librosa.load(path, sr =16000)\n",
    "\n",
    "'''\n",
    "We have used the sampling rate (sr) of 16000 to read the above audio data. An audio wave of 2 seconds with a sampling rate of 16,000 will have 32,000 samples.\n",
    "'''\n",
    "\n",
    "#__Find the duration of the audio clips__\n",
    "duration1 = librosa.get_duration(y=emergency, sr=16000)\n",
    "\n",
    "\n",
    "\n",
    "duration2 = librosa.get_duration(y=non_emergency, sr=16000)\n",
    "\n",
    "\n",
    "print(\"Duration of an emergency and Non Emergency (in min):\",duration1/60,duration2/60)\n",
    "\n",
    "'''\n",
    "## Preparing Data\n",
    "\n",
    "Let us break the audio into chunks of 2 seconds. So, let us define the function for the same task\n",
    "\n",
    "'''\n",
    "def prepare_data(audio_data, num_of_samples=32000, sr=16000):\n",
    "  \n",
    "  data=[]\n",
    "  for offset in range(0, len(audio_data), sr):\n",
    "    start = offset\n",
    "    end   = offset + num_of_samples\n",
    "    chunk = audio_data[start:end]\n",
    "    \n",
    "    if(len(chunk)==32000):\n",
    "      data.append(chunk)\n",
    "    \n",
    "  return data\n",
    "\n",
    "# prepare audio chunks\n",
    "emergency = prepare_data(emergency)\n",
    "non_emergency = prepare_data(non_emergency)\n",
    "\n",
    "print(\"No. of Chunks of Emergency and Non Emergency:\",len(emergency),len(non_emergency))\n",
    "\n",
    "ipd.Audio(emergency[136],rate=16000)\n",
    "\n",
    "ipd.Audio(non_emergency[10],rate=16000)\n",
    "\n",
    "## Visualization of Audio Data\n",
    "plt.figure(figsize=(14,4))\n",
    "plt.plot(np.linspace(0, 2, num=32000),emergency[103])\n",
    "plt.title('Emergency')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(14,4))\n",
    "plt.plot(np.linspace(0, 2, num=32000),non_emergency[102])\n",
    "plt.title('Non Emergency')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Amplitude')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#__Combine Emergecy and Non Emergency chunks__\n",
    "audio = np.concatenate([emergency,non_emergency])\n",
    "\n",
    "# assign labels \n",
    "labels1 = np.zeros(len(emergency))\n",
    "labels2 = np.ones(len(non_emergency))\n",
    "\n",
    "# concatenate labels\n",
    "labels = np.concatenate([labels1,labels2])\n",
    "\n",
    "print(audio.shape)\n",
    "\n",
    "#**Split into train and validation set**\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_tr, x_val, y_tr, y_val = train_test_split(np.array(audio),np.array(labels),\n",
    "                                            stratify=labels,test_size = 0.1,\n",
    "                                            random_state=777,shuffle=True)\n",
    "\n",
    "print(x_tr.shape, x_val.shape)\n",
    "\n",
    "x_tr_features  = x_tr.reshape(len(x_tr),-1,1)\n",
    "x_val_features = x_val.reshape(len(x_val),-1,1)\n",
    "\n",
    "print(\"Reshaped Array Size\",x_tr_features.shape)\n",
    "\n",
    "'''\n",
    "## Model Architecture\n",
    "\n",
    "Let's define the model architecture using conv1D layers  and the time domain features.\n",
    "\n",
    "'''\n",
    "\n",
    "from keras.layers import Input, Conv1D, Dropout, MaxPooling1D, GlobalMaxPool1D, Dense\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# CNN based deep learning model architecture\n",
    "def conv_model(x_tr):\n",
    "  \n",
    "  inputs = Input(shape=(x_tr.shape[1],x_tr.shape[2]))\n",
    "\n",
    "  #First Conv1D layer\n",
    "  conv = Conv1D(8, 13, padding='same', activation='relu')(inputs)\n",
    "  conv = Dropout(0.3)(conv)\n",
    "  conv = MaxPooling1D(2)(conv)\n",
    "\n",
    "  #Second Conv1D layer\n",
    "  conv = Conv1D(16, 11, padding='same', activation='relu')(conv)\n",
    "  conv = Dropout(0.3)(conv)\n",
    "  conv = MaxPooling1D(2)(conv)\n",
    "\n",
    "  # Global MaxPooling 1D\n",
    "  conv = GlobalMaxPool1D()(conv)\n",
    "\n",
    "  #Dense Layer \n",
    "  conv = Dense(16, activation='relu')(conv)\n",
    "  outputs = Dense(1,activation='sigmoid')(conv)\n",
    "\n",
    "  model = Model(inputs, outputs)\n",
    "  \n",
    "  model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['acc'])\n",
    "  model_checkpoint = ModelCheckpoint('best_model.hdf5', monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "  \n",
    "  return model, model_checkpoint\n",
    "\n",
    "model, model_checkpoint = conv_model(x_tr_features)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# model training\n",
    "history = model.fit(x_tr_features, y_tr ,epochs=10, \n",
    "                    callbacks=[model_checkpoint], batch_size=32, \n",
    "                    validation_data=(x_val_features,y_val))\n",
    "\n",
    "# load the best model weights\n",
    "model.load_weights('best_model.hdf5')\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# check model's performance on the validation set\n",
    "_, acc = model.evaluate(x_val_features,y_val)\n",
    "print(\"Validation Accuracy:\",acc)\n",
    "\n",
    "# input audio\n",
    "\n",
    "ind=35\n",
    "test_audio = x_val[ind]\n",
    "ipd.Audio(test_audio,rate=16000)\n",
    "\n",
    "# classification\n",
    "feature = x_val_features[ind]\n",
    "prob = model.predict(feature.reshape(1,-1,1))\n",
    "if (prob[0][0] < 0.5):\n",
    "  pred='emergency'\n",
    "else:\n",
    "  pred='non emergency' \n",
    "\n",
    "print(\"Prediction:\",pred)\n",
    "\n",
    "# reshape chunks\n",
    "x_tr_features  = x_tr.reshape(len(x_tr),-1,160)\n",
    "x_val_features = x_val.reshape(len(x_val),-1,160)\n",
    "\n",
    "print(\"Reshaped Array Size\",x_tr_features.shape)\n",
    "\n",
    "from keras.layers import LSTM\n",
    "\n",
    "# LSTM based deep learning model architecture\n",
    "def lstm_model(x_tr):\n",
    "  \n",
    "  inputs = Input(shape=(x_tr.shape[1],x_tr.shape[2]))\n",
    "\n",
    "  #lstm\n",
    "  x = LSTM(128)(inputs)\n",
    "  x = Dropout(0.3)(x)\n",
    "  \n",
    "  #dense\n",
    "  x= Dense(64,activation='relu')(x)\n",
    "  x= Dense(1,activation='sigmoid')(x)\n",
    "  \n",
    "  model = Model(inputs, x)\n",
    "\n",
    "  model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['acc'])\n",
    "  \n",
    "  return model\n",
    "\n",
    "model = lstm_model(x_tr_features)\n",
    "model.summary()\n",
    "\n",
    "mc = ModelCheckpoint('best_model.hdf5', monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "history=model.fit(x_tr_features, y_tr, epochs=10, \n",
    "                  callbacks=[mc], batch_size=32, \n",
    "                  validation_data=(x_val_features,y_val))\n",
    "\n",
    "\n",
    "# load best model weights\n",
    "model.load_weights('best_model.hdf5')\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "_,acc = model.evaluate(x_val_features,y_val)\n",
    "print(\"Accuracy:\",acc)\n",
    "\n",
    "'''\n",
    "## Spectrogram Features\n",
    "\n",
    "Let us define a function that computes the spectrogram. Before that, we need to understand how the spectrogram is computed.\n",
    "\n",
    "Spectrogram accepts the raw audio wave and then breaks it into chunks or windows and then applies FFT on each window to compute the frequencies.\n",
    "\n",
    "Coming to the parameters for computing spectrogram: \n",
    "\n",
    "* nperseg = Size of the window i.e. number of samples in each chunk\n",
    "* noverlap= Number of overlapping samples between each window\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "def log_specgram(audio, sample_rate, eps=1e-10):\n",
    "    nperseg  = 320\n",
    "    noverlap = 160\n",
    "\n",
    "    freqs, times, spec = scipy.signal.spectrogram(audio,fs=sample_rate, nperseg=nperseg,noverlap=noverlap)\n",
    "    return freqs, times, np.log(spec.T.astype(np.float32) + eps)\n",
    "\n",
    "def plot(spectrogram,label):\n",
    "  fig = plt.figure(figsize=(14, 8))\n",
    "  ax = fig.add_subplot(211)\n",
    "  ax.imshow(spectrogram.T, aspect='auto', extent=[times.min(), times.max(), freqs.min(), freqs.max()])\n",
    "  ax.set_title('Spectrogram of '+label)\n",
    "  ax.set_ylabel('Freqs in Hz')\n",
    "  ax.set_xlabel('Seconds')\n",
    "\n",
    "  freqs, times, spectrogram = log_specgram(emergency[300], sample_rate)\n",
    "plot(spectrogram,\"emergency\")\n",
    "\n",
    "freqs, times, spectrogram = log_specgram(non_emergency[300], sample_rate)\n",
    "plot(spectrogram,\"non emergency\")\n",
    "\n",
    "print(spectrogram.shape)\n",
    "\n",
    "def extract_spectrogram_features(x_tr):\n",
    "  features=[]\n",
    "  for i in x_tr:\n",
    "    _, _, spectrogram = log_specgram(i, sample_rate)\n",
    "    \n",
    "    mean = np.mean(spectrogram, axis=0)\n",
    "    std = np.std(spectrogram, axis=0)\n",
    "    spectrogram = (spectrogram - mean) / std\n",
    "    \n",
    "    features.append(spectrogram)\n",
    "\n",
    "  return np.array(features)\n",
    "\n",
    "x_tr_features  = extract_spectrogram_features(x_tr)\n",
    "x_val_features = extract_spectrogram_features(x_val)\n",
    "\n",
    "model_2 = lstm_model(x_tr_features)\n",
    "\n",
    "mc = ModelCheckpoint('best_model.hdf5', monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "model_2.summary()\n",
    "\n",
    "\n",
    "#Train the model\n",
    "history=model_2.fit(x_tr_features, y_tr, \n",
    "                    epochs=10, callbacks=[mc], batch_size=32, \n",
    "                    validation_data=(x_val_features,y_val))\n",
    "\n",
    "model_2.load_weights('best_model.hdf5')\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "_,acc = model_2.evaluate(x_val_features,y_val)\n",
    "print(\"Accuracy:\",acc)\n",
    "\n",
    "model_3, mc = conv_model(x_tr_features)\n",
    "\n",
    "model_3.summary()\n",
    "\n",
    "history=model_3.fit(x_tr_features, y_tr, \n",
    "                    epochs=10, callbacks=[mc], batch_size=32, \n",
    "                    validation_data=(x_val_features,y_val))\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "model_3.load_weights('best_model.hdf5')\n",
    "\n",
    "# model's performance on the validation set\n",
    "_,acc = model_3.evaluate(x_val_features,y_val)\n",
    "print(\"Accuracy:\",acc)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
